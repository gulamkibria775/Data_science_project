{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulamkibria775/Data_science_project/blob/main/Data_science_project/resnet_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbUL5gK02vEI",
        "outputId": "252c72cc-b6a1-4a4a-8372-8bc6fea7521d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/driver; to attempt to forcibly remount, call drive.mount(\"/content/driver\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/driver\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(x, filters, kernel_size=3):\n",
        "    # Shortcut\n",
        "    shortcut = x\n",
        "\n",
        "    # First layer\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Second layer\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Add the shortcut to the main path\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "jQUlnsdRoiaE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_block(x, filters, kernel_size=3, strides=2):\n",
        "    # Shortcut\n",
        "    shortcut = x\n",
        "\n",
        "    # First layer\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Second layer\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Shortcut path\n",
        "    shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
        "    shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    # Add the shortcut to the main path\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "T66Fuebfoics"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet50(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolutional layer\n",
        "    x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "    # Stacking convolutional and identity blocks\n",
        "    x = convolutional_block(x, 64)\n",
        "    x = identity_block(x, 64)\n",
        "    x = identity_block(x, 64)\n",
        "\n",
        "    x = convolutional_block(x, 128)\n",
        "    x = identity_block(x, 128)\n",
        "    x = identity_block(x, 128)\n",
        "\n",
        "    x = convolutional_block(x, 256)\n",
        "    x = identity_block(x, 256)\n",
        "    x = identity_block(x, 256)\n",
        "    x = identity_block(x, 256)\n",
        "\n",
        "    x = convolutional_block(x, 512)\n",
        "    x = identity_block(x, 512)\n",
        "    x = identity_block(x, 512)\n",
        "\n",
        "    # Global average pooling and fully connected layer\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "cibPcQktoifS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Assuming you have defined the build_resnet50 function and set up your data directories\n",
        "\n",
        "# Set up data generators\n",
        "train_data_dir = '/content/driver/MyDrive/All_data_file/ResNet50-master/rooms_dataset'\n",
        "# validation_data_dir = 'path/to/validation_data'\n",
        "# test_data_dir = 'path/to/test_data'\n",
        "\n",
        "input_shape = (224, 224, 3)  # Adjust the input shape according to your images\n",
        "num_classes = 3  # Adjust the number of classes in your dataset\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# validation_generator = validation_datagen.flow_from_directory(\n",
        "#     validation_data_dir,\n",
        "#     target_size=input_shape[:2],\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='categorical'\n",
        "# )\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Build and compile the ResNet50 model\n",
        "resnet50_model = build_resnet50(input_shape, num_classes)\n",
        "\n",
        "resnet50_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 5\n",
        "\n",
        "history = resnet50_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    # validation_data=validation_generator,\n",
        "    # validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = resnet50_model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "\n",
        "# Save the trained model if needed\n",
        "resnet50_model.save('resnet50_model.h5')\n"
      ],
      "metadata": {
        "id": "eYjsAWw5oih3",
        "outputId": "8b50fa74-ae58-4e79-b5e6-9e5357d31a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 415 images belonging to 3 classes.\n",
            "Found 57 images belonging to 3 classes.\n",
            "Epoch 1/5\n",
            "12/12 [==============================] - 106s 7s/step - loss: 2.2145 - accuracy: 0.3568\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - 72s 6s/step - loss: 1.1132 - accuracy: 0.4517\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - 67s 5s/step - loss: 1.0537 - accuracy: 0.4674\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - 69s 6s/step - loss: 0.9633 - accuracy: 0.5170\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - 69s 6s/step - loss: 0.9494 - accuracy: 0.5509\n",
            "2/2 [==============================] - 3s 849ms/step - loss: 3.4114 - accuracy: 0.1930\n",
            "Test Accuracy: 0.19298245012760162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZzEfN3_boilY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkexf1BAC1L8N6q9fLtv+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}